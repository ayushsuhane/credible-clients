{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def F_LinearRegression(X_train, y_train, X_test, y_test):\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X=X_train, y=y_train)\n",
    "    y_hat = linreg.predict(X_test)\n",
    "    y_hat = np.rint(np.absolute(y_hat)).astype(int)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def F_LogisticRegression(X_train, y_train, X_test, y_test):\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X=X_train, y=y_train)\n",
    "    y_hat = logreg.predict(X_test)\n",
    "    y_hat = np.rint(np.absolute(y_hat)).astype(int)\n",
    "    return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def F_GaussianNB(X_train, y_train, X_test, y_test):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X=X_train, y=y_train)\n",
    "    y_hat = gnb.predict(X_test)\n",
    "    y_hat = np.rint(np.absolute(y_hat)).astype(int)\n",
    "    return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def F_KNN(X_train, y_train, X_test, y_test):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_hat = knn.predict(X_test)\n",
    "    y_hat = np.rint(np.absolute(y_hat)).astype(int)\n",
    "    return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def F_RandomForest(X_train, y_train, X_test, y_test):\n",
    "    rf = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_hat = rf.predict(X_test)\n",
    "    y_hat = np.rint(np.absolute(y_hat)).astype(int)\n",
    "    return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "def F_Neural(X_train, y_train, X_test, y_test):\n",
    "    n = X_train.shape[1]\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(n,n,n),max_iter=500) \n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_hat = mlp.predict(X_test)\n",
    "    y_hat = np.rint(np.absolute(y_hat)).astype(int)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Input and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data/credit-data.csv', dtype=np.int, delimiter=',', skiprows=1)\n",
    "X, y = data[:, 1:-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for all the methods to test\n",
    "functions = {'LinearRegression':F_LinearRegression,\n",
    "            'LogisticRegression':F_LogisticRegression,\n",
    "            'NaiveBayes': F_GaussianNB,\n",
    "            'KNN': F_KNN,\n",
    "            'RandomForest': F_RandomForest,\n",
    "            'ANN': F_Neural}\n",
    "labels = {'LinearRegression':'LR',\n",
    "            'LogisticRegression':'LogR',\n",
    "            'NaiveBayes': 'GNB',\n",
    "            'KNN': 'KNN',\n",
    "            'RandomForest': 'RF',\n",
    "            'ANN': 'ANN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "\n",
    "from collections import defaultdict\n",
    "acc, pre, re = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "                                              \n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in crossvalidation.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    for key in functions:\n",
    "        y_hat = functions[key](X_train, y_train, X_test, y_test)\n",
    "        accuracy = 100 * accuracy_score(y_test, y_hat)\n",
    "        precision = 100 * precision_score(y_test, y_hat, average='weighted')\n",
    "        recall = 100 * recall_score(y_test, y_hat, average='weighted')\n",
    "    \n",
    "        acc[labels[key]].append(accuracy)\n",
    "        pre[labels[key]].append(precision)\n",
    "        re[labels[key]].append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Report with the average accuracy, average precision, average recall with different methods\n",
    "mean_accuracy, mean_precision, mean_recall, std = defaultdict(list), defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "for key in labels:\n",
    "    mean_accuracy[labels[key]].append([np.mean(acc[labels[key]]), np.std(acc[labels[key]])])\n",
    "    mean_precision[labels[key]].append([np.mean(pre[labels[key]]), np.std(pre[labels[key]])])\n",
    "    mean_recall[labels[key]].append([np.mean(re[labels[key]]), np.std(re[labels[key]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = defaultdict(list)\n",
    "for key in labels:\n",
    "    all_data[key] = mean_accuracy[labels[key]][0] + mean_precision[labels[key]][0] + mean_recall[labels[key]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  Accuracy STD Precision STD Recall STD\n",
      "LinearRegression [79.87, 0.6659496143770068, 78.46910156623676, 0.9891565553692367, 79.87, 0.6659496143770068]\n",
      "LogisticRegression [77.87, 0.36733272837215925, 60.65266459189714, 0.5863721327724927, 77.87, 0.36733272837215925]\n",
      "NaiveBayes [37.83, 0.7225264316580022, 74.01013150582432, 1.0959227749870049, 37.83, 0.7225264316580022]\n",
      "KNN [75.59333333333333, 0.4787251589145706, 70.83635666127176, 0.7074542567755447, 75.59333333333333, 0.4787251589145706]\n",
      "RandomForest [80.48666666666666, 0.43594087264724973, 78.27237458367203, 0.5287942316150301, 80.48666666666666, 0.43594087264724973]\n",
      "ANN [67.01333333333332, 9.417226532029241, 67.54305044028047, 1.3921931060680532, 67.01333333333332, 9.417226532029241]\n"
     ]
    }
   ],
   "source": [
    "print(\"Method  Accuracy STD Precision STD Recall STD\")\n",
    "for item in all_data:\n",
    "    print (item, all_data[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is the best model with highest recall, precision and accuracy metrics. The next step would be to build a model with random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
